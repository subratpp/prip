{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Problem 5\n",
    "### Subrat Prasad Panda, CS1913"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design your own SVM which can solve a non-linearly separable overlapped\n",
    "multi-class problem. You may use an available optimization problem solver. You are encouraged to\n",
    "choose a kernel and parameter on your own. Now show the 5-fold cross validated performance of your\n",
    "SVM in the following cases.\n",
    "\n",
    "- Download the Iris flower dataset and train your SVM on class 1 and 3. What is the test performance? Can you show the learned decision boundary for a certain fold if the third and forthfeature of the dataset is used? As the problem is linearly separable you may consider a linear SVM which does not use a kernel.\n",
    "- Now train your SVM to classify all three classes of the Iris dataset. What is the average test accuracy? Remember the classes are overlapped in nature.\n",
    "- Create a subset of the MNIST dataset (consider only the training set) by uniformly sampling (without replacement) 500 points from each classes. Can you train your SVM on such a dataset? What is the average accuracy on such a dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "#Data processing\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVXOPT Library\n",
    "The CVXOPT library solves the Wolfe dual soft margin constrained optimisation with the following form:\n",
    "$$ \\underset{\\alpha}{min} \\frac{1}{2} \\alpha^T (yy^TK) \\alpha - 1^T \\alpha $$\n",
    "$$s.t. -\\alpha_n \\preceq 0, y.\\alpha = 0$$\n",
    "Where for CVOPT the variables will be,\n",
    "- K: is the Gram matrix of all possible do products of vector $x_n$.\n",
    "- P: $(yy^TG)$ matrix of size N X N\n",
    "- q: $-1^T$ a vector of size N X 1\n",
    "- G: -diag[1] a diagonal matrix of -1 of size N X N\n",
    "- h: 0 vector of size N X 1\n",
    "- b: 0 a scalar\n",
    "- A: y label vector of size N X 1\n",
    "- N: Number of samples points\n",
    "\n",
    "The P, q, G, A and h will be used to call CVOPT API. The $\\alpha$ is the Langragian variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svm():\n",
    "\n",
    "    def __init__(self, kernel='linear', C=0.0, gamma=1.0, degree=3):\n",
    "        self.C = C #Hyperparameter, C=0 means Hard SVM\n",
    "        self.gamma = gamma #Gaussian Kernel Multimpier 1/sigma\n",
    "        self.degree = degree #Degree of Polynomial kernel\n",
    "        self.kernel = kernel #type of kernel\n",
    "\n",
    "    def linear_kernel(self, x, y):\n",
    "        return np.dot(x, y)\n",
    "\n",
    "    def poly_kernel(self, x, y, degree=3):\n",
    "        return (np.dot(x, y) + 1) ** degree\n",
    "\n",
    "    def rbf_kernel(self, x, y, gamma=0.5):\n",
    "        return np.exp(-gamma*linalg.norm(x - y) ** 2 )\n",
    "    \n",
    "    # Compute the kernel matrix K\n",
    "    def compute_kernel(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Gram matrix or Kernel trick.\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                if self.kernel == 'linear':\n",
    "                    K[i, j] = self.linear_kernel(X[i], X[j])\n",
    "                if self.kernel=='rbf':\n",
    "                    K[i, j] = self.rbf_kernel(X[i], X[j], self.gamma)   # Kernel trick.\n",
    "                    self.C = None   # Not used in gaussian kernel.\n",
    "                if self.kernel == 'poly':\n",
    "                    K[i, j] = self.polyn_kernel(X[i], X[j], self.degree)\n",
    "        return K\n",
    "\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        K =  self.compute_kernel(X) #Kernel Matrix\n",
    "        # Converting into cvxopt format:\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1, n_samples))\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        if self.C is None or self.C==0: # For C=0, it's Hard margin SVM\n",
    "            G = cvxopt.matrix(np.identity(n_samples) * -1)\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else: # Restricting the langragina variable (alpha) with parameter C.\n",
    "            G = cvxopt.matrix(np.vstack((np.identity(n_samples) * -1, np.identity(n_samples)))) # 0 <= alpha <= C\n",
    "            h = cvxopt.matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C))) #[0, 0 , C ,C]\n",
    "\n",
    "        # Setting options of solver:\n",
    "        cvxopt.solvers.options['show_progress'] = False\n",
    "        cvxopt.solvers.options['abstol'] = 1e-10 # (10^-10) very small number\n",
    "        cvxopt.solvers.options['reltol'] = 1e-10\n",
    "        cvxopt.solvers.options['feastol'] = 1e-10\n",
    "\n",
    "        # Solve QP problem:\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        #Solutions\n",
    "        # Lagrange multipliers: Vector on N multipliers\n",
    "        alphas = np.ravel(solution['x']) # Flatten the matrix into a vector of all the Langrangian multipliers.\n",
    "\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = alphas > 1e-5 #False and True vector showing the support vectors\n",
    "        index_sv = np.arange(len(alphas))[sv] #index of support vectors\n",
    "        \n",
    "        #Store alpha values and support vector values\n",
    "        self.alphas = alphas[sv] #values of support vectors\n",
    "        self.sv = X[sv] #Store support vectors\n",
    "        self.sv_y = y[sv] #store class of support vectors\n",
    "\n",
    "        # Bias(b of Wx+b):\n",
    "        self.b = 0\n",
    "        for n in range(len(self.alphas)): # For all support vectors:\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.alphas * self.sv_y * K[index_sv[n], sv])\n",
    "        self.b = self.b / len(self.alphas)\n",
    "        \n",
    "         # Weight vector\n",
    "        if self.kernel == 'linear':\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.alphas)):\n",
    "                self.w += self.alphas[n] * self.sv_y[n] * self.sv[n]\n",
    "        print(\"Training Done!\")\n",
    "\n",
    "\n",
    "    def predict(self, X): # Calculates the hypothesis\n",
    "        y_predict = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            value = 0\n",
    "            for a, sv_y, sv in zip(self.alphas, self.sv_y, self.sv): # a : Lagrange multipliers, sv : support vectors.\n",
    "                if self.kernel == 'linear':\n",
    "                    value += a * sv_y * self.linear_kernel(X[i], sv)\n",
    "                if self.kernel=='rbf':\n",
    "                    value += a * sv_y * self.rbf_kernel(X[i], sv, self.gamma)   # Kernel trick.\n",
    "                    self.C = None   # Not used in gaussian kernel.\n",
    "                if self.kernel == 'poly':\n",
    "                    value += a * sv_y * self.poly_kernel(X[i], sv, self.degree)\n",
    "\n",
    "            y_predict[i] = value\n",
    "        return np.sign(y_predict + self.b) #returns Hypothesis: sign(sum^S a * y * kernel + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X: Rows are the samples and columns are the features\n",
    "\n",
    "y: row vector of class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done!\n",
      "Total Correct Predictions: 4\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([-1, -1, 1, 1]) #Row Vector\n",
    "y = y.astype('float')\n",
    "test = svm(kernel='linear', C=0.0, gamma=1.0, degree=3)\n",
    "test.train(X, y)\n",
    "y_predict = test.predict(X)\n",
    "correct_predictions = np.sum(y_predict == y) #Number of correct predictions\n",
    "print(f\"Total Correct Predictions: {correct_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IRIS Dataset with only Class 1 and Class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV IRIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read IRIS Dataset\n",
    "data = []\n",
    "with open('datasets/iris.data','r')as f:\n",
    "    file = csv.reader(f)\n",
    "    for row in file:\n",
    "        if row[4] == 'Iris-setosa':\n",
    "            row[4] = '1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data.append(float_list)\n",
    "        \n",
    "        elif row[4] == 'Iris-virginica':\n",
    "            row[4] = '-1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data.append(float_list)\n",
    "\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data) #Shuffle the input data\n",
    "num_of_sample = len(data)\n",
    "\n",
    "# #Generate Test and Training Data from the Sample 80-20%\n",
    "# test_data = data[:int(num_of_sample*0.20)]\n",
    "# training_data = data[int(num_of_sample*0.20):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and y Matrix from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:4] # take features\n",
    "y = np.ravel(data[:, -1:]) #take the class labels and flaten to make row vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test with 5-Folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done!\n",
      "Training Done!\n",
      "Training Done!\n",
      "Training Done!\n",
      "Training Done!\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(5, True, 1) # prepare 5 fold cross validation\n",
    "\n",
    "iris1 = svm(kernel='linear')\n",
    "\n",
    "accuracy = 0 #init mse sum with 0\n",
    "for train, test in kfold.split(X):\n",
    "    #kfold:True to use the z values from previous training\n",
    "    iris1.train(X[train], y[train]) #train the svm\n",
    "    y_predict = iris1.predict(X[test])\n",
    "    correct_predictions = np.sum(y_predict == y[test]) #Number of correct predictions\n",
    "    accuracy += (correct_predictions/len(y[test]))*100 #percentage accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#Compute the average accuracy over 5 folds of testing\n",
    "avg_accuracy = accuracy/5\n",
    "print(f\"Average Accuracy: {avg_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the linear classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prepare data for plotting\n",
    "X1 = X[y == 1]\n",
    "X1 = X1[:, 2:4] # +1 classes\n",
    "\n",
    "X2 = X[y == -1]\n",
    "X2 = X2[:, 2:4] # -1 classes\n",
    "\n",
    "\n",
    "def compute_y(x, w, b, c = 0): #coordinate (x1, x2)\n",
    "    return ( (5.8*w[0] + 3*w[1] + w[2] * x + b - c) / -w[3] ) #w.X1 + b = c\n",
    "    # 5.8 and 3 is the average of feature1 and feature2\n",
    "\n",
    "\n",
    "fig = plt.figure()  # create a figure object\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# Format plot area:\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "x1_min, x1_max = X1.min(), X1.max()\n",
    "x2_min, x2_max = X2.min(), X2.max()\n",
    "# ax.set(xlim=(x1_min, x1_max), ylim=(x2_min, x2_max))\n",
    "\n",
    "# Labels\n",
    "plt.xlabel('$feature 3$', fontsize=9)\n",
    "plt.ylabel('$feature 4$', fontsize=9)\n",
    "\n",
    "# Add the plots:\n",
    "plt.plot(X1[:, 0], X1[:, 1], marker='x',markersize=5, color='lightblue',linestyle='none', label=\"+\")\n",
    "plt.plot(X2[:, 0], X2[:, 1], marker='o',markersize=4, color='darkorange',linestyle='none', label=\"-\")\n",
    "\n",
    "# #Plot Support vectors\n",
    "# plt.scatter(iris1.sv[:, 2], iris1.sv[:, 3], s=60, color=\"blue\")   \n",
    "\n",
    "w = iris1.w\n",
    "b = iris1.b\n",
    "x1_min, x1_max = ax.get_xlim()\n",
    "\n",
    "y1 = compute_y(x1_min, w, b)\n",
    "y2 = compute_y(x1_max, w, b)\n",
    "plt.plot([x1_min, x1_max], [y1, y2], \"k\", label = 'Margin') #Plot Margin\n",
    "\n",
    "# # Margin +: w.x + b = 1\n",
    "# y3 = compute_y(x1_min, w, b, 1)\n",
    "# y4 = compute_y(x1_max, w, b, 1)\n",
    "# plt.plot([x1_min, x1_max], [y3, y4], \"k--\")\n",
    "\n",
    "# # Margin -: w.x + b = -1\n",
    "# y5 = compute_y(x1_min, w, b, -1)\n",
    "# y6 = compute_y(x1_max, w, b, -1)\n",
    "# plt.plot([x1_min, x1_max], [y5, y6], \"k--\")\n",
    "\n",
    "plt.xlim([0.5, 7])\n",
    "plt.ylim([-0.5, 3])\n",
    "plt.legend()\n",
    "plt.title(\"SVM IRIS Plot with feature 3 and feature 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IRIS Data with all classes\n",
    "One vs all Method is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For IRIS Setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done!\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#Read IRIS Dataset\n",
    "data1 = []\n",
    "with open('datasets/iris.data','r') as f:\n",
    "    file = csv.reader(f)\n",
    "    for row in file:\n",
    "        if row[4] == 'Iris-setosa':\n",
    "            row[4] = '1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data1.append(float_list)\n",
    "        else: #Iris-virginica 'Iris-versicolor' # 'Iris-setosa'\n",
    "            row[4] = '-1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data1.append(float_list)\n",
    "\n",
    "data1 = np.array(data1)\n",
    "X = data1[:,:4] # take features\n",
    "y = np.ravel(data1[:, -1:]) #take the class labels and flaten to make row vector\n",
    "\n",
    "iris2_1 = svm(kernel='rbf')\n",
    "iris2_1.train(X, y) #train the svm\n",
    "y_predict1 = iris2_1.predict(X)\n",
    "correct_predictions = np.sum(y_predict1 == y) #Number of correct predictions\n",
    "accuracy1 = (correct_predictions/len(y))*100 #percentage accuracy\n",
    "print(f\"Accuracy: {accuracy1}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done!\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#Read IRIS Dataset\n",
    "data1 = []\n",
    "with open('datasets/iris.data','r') as f:\n",
    "    file = csv.reader(f)\n",
    "    for row in file:\n",
    "        if row[4] == 'Iris-virginica':\n",
    "            row[4] = '1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data1.append(float_list)\n",
    "        else: #Iris-virginica 'Iris-versicolor' # 'Iris-setosa'\n",
    "            row[4] = '-1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data1.append(float_list)\n",
    "\n",
    "data1 = np.array(data1)\n",
    "X = data1[:,:4] # take features\n",
    "y = np.ravel(data1[:, -1:]) #take the class labels and flaten to make row vector\n",
    "\n",
    "iris2_2 = svm(kernel='rbf')\n",
    "iris2_2.train(X, y) #train the svm\n",
    "y_predict2 = iris2_2.predict(X)\n",
    "correct_predictions = np.sum(y_predict2 == y) #Number of correct predictions\n",
    "accuracy2 = (correct_predictions/len(y))*100 #percentage accuracy\n",
    "print(f\"Accuracy: {accuracy2}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done!\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "with open('datasets/iris.data','r') as f:\n",
    "    file = csv.reader(f)\n",
    "    for row in file:\n",
    "        if row[4] == 'Iris-versicolor':\n",
    "            row[4] = '1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data1.append(float_list)\n",
    "        else: #Iris-virginica 'Iris-versicolor' # 'Iris-setosa'\n",
    "            row[4] = '-1'\n",
    "            float_list = list(map(float, row)) \n",
    "            data1.append(float_list)\n",
    "\n",
    "data1 = np.array(data1)\n",
    "X = data1[:,:4] # take features\n",
    "y = np.ravel(data1[:, -1:]) #take the class labels and flaten to make row vector\n",
    "\n",
    "iris2_3 = svm(kernel='rbf')\n",
    "iris2_3.train(X, y) #train the svm\n",
    "y_predict3 = iris2_3.predict(X)\n",
    "correct_predictions = np.sum(y_predict3 == y) #Number of correct predictions\n",
    "accuracy3 = (correct_predictions/len(y))*100 #percentage accuracy\n",
    "print(f\"Accuracy: {accuracy3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggegrate all the prediction data from 3 (one vs all) classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = [0] * len(y)\n",
    "for row in range(len(y)):\n",
    "    if y_predict1[row] == 1:\n",
    "        y_result[row] = \"Iris-setosa\"\n",
    "    if y_predict2[row] == 1:\n",
    "        y_result[row] = \"Iris-virginica\"\n",
    "    if y_predict3[row] == 1:\n",
    "        y_result[row] = \"Iris-versicolor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Final Prediction: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#Read IRIS Dataset\n",
    "correct_predictions = 0\n",
    "i = 0\n",
    "with open('datasets/iris.data','r')as f:\n",
    "    file = csv.reader(f)\n",
    "    for row in file:\n",
    "        if y_result[i] == row[4]:\n",
    "            correct_predictions +=1\n",
    "        i +=1\n",
    "\n",
    "accuracy4 = (correct_predictions/len(y_result))*100 #percentage accuracy\n",
    "print(f\"Accuracy of Final Prediction: {accuracy4}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The prediction after 3 classifiers is found to be 100% using RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3: MNIST dataset can similarly be trained, there 10 classifiers need to be used for one vs all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
