{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "### Subrat Prasad Panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "Letâ€™s say you want to buy a new flat and thus need to estimate a bank loan. You surveyed the newspapers for the price of 10 random flats spread across your city. However, the surveyed flats are of different sizes having diverse range of essential amenities. Thus, you created the following Table 1 listing the size of a flat, the number of bedrooms in that flat, and the corresponding price. You want to buy a flat which is about 950-1050 sq. ft. in size having either 2 or 3 bedrooms. Estimate the upper and lower limit of the bank loan given the data in Table 1 (table1.csv).\n",
    "\n",
    "    2.2.a Write a code which will provide you the least square estimation by solving the closed form solution for such problems.\n",
    "\n",
    "    2.2.b Write a code which will provide you the least square estimate by solving the problem using a gradient decent approach. Plot the convergence of the model parameters over successive iterations.\n",
    "\n",
    "    2.2.c Plot the flat prices as a function of flat size and number of bedrooms. Draw the least square estimators obtained respectively by solving the closed form solution and by gradient descent. Plot your least square estimations for the bank loan in both cases.\n",
    "\n",
    "    2.2.d Download the Portland House Price Prediction Dataset https://www.kaggle.com/ kennethjohn/housingprice. Report the 10-fold cross validation mean squared error of your least square estimation model trained by gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries: numpy, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "np.set_printoptions(suppress=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equation for solving the closed form:\n",
    "\\begin{equation*}\n",
    "Xz = y \\\\\n",
    "z = (X^{T}X)^{-1}X^{T}y\n",
    "\\end{equation*}\n",
    "#### Predicted values will be:\n",
    "\\begin{equation*}\n",
    "Xz = \\hat{y} \\\\\n",
    "where, z = [z_0, z_1, z_2]^T\n",
    "\\end{equation*}\n",
    "$z$ needs to be computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    '''\n",
    "    #1. Separate the data into X:(house size, #of bed rooms), y:housing price\n",
    "    #2. Standarize the data\n",
    "    #3. Concatenate column vector of 1 to the matrix X\n",
    "    '''\n",
    "    #1. Separate X and y into\n",
    "    X = data[:, :2].copy()\n",
    "    y = data[:, 2:].copy()\n",
    "\n",
    "    #2. Feature Scaling using \n",
    "    meanX = np.mean(X, axis=0)\n",
    "    stdX = np.std(X, axis=0)\n",
    "    X = (X - meanX)/stdX\n",
    "\n",
    "    #3. add column of 1's to the matrix X_\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "    return X, y, meanX, stdX\n",
    "\n",
    "def mse(X, y, z):\n",
    "    '''\n",
    "    Compute Mean of Squared Error\n",
    "    '''\n",
    "    np.seterr(over='raise')\n",
    "    n = X.shape[0] #number of samples\n",
    "    y_hat = np.dot(X, z)\n",
    "    loss = y_hat - y\n",
    "    J = np.sum(loss ** 2) / (2 * n)  # squared error function\n",
    "    return J\n",
    "\n",
    "def batch_gradient_descent(X, y, learning_rate, epochs, verbose=False, kfold=False, **kwargs):\n",
    "    '''\n",
    "    Function to perform Batch Gradient Descent for Linear Regression.\n",
    "    '''\n",
    "    #Cache the data to plot\n",
    "    squared_error = []\n",
    "    z_cache = []\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Initialize the z: Coefficient Vector\n",
    "    if not kfold:\n",
    "        z = np.random.rand(3,1) #Initialize z with random values\n",
    "    else:\n",
    "        z = kwargs['z'] # Use z values from previous training in KFolds validation\n",
    "    #Plot error while training(optional)\n",
    "    if verbose:\n",
    "        %matplotlib inline\n",
    "        fig1 = plt.figure()  # create a figure object\n",
    "        ax1 = fig1.add_subplot(1, 1, 1)  # create an axes object in the figure\n",
    "        ax1.set_title(\"Squared Error vs Epoch\")\n",
    "        ax1.set_xlabel('Epoch', fontweight ='bold') \n",
    "        ax1.set_ylabel('Squared Error', fontweight ='bold') \n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        # y_hat is the predicted value\n",
    "        y_hat = np.dot(X, z)\n",
    "        loss = y_hat - y\n",
    "        J = np.sum(loss ** 2) / (2 * n)  # squared error function\n",
    "        squared_error.append(J) #store cost value over iteration   \n",
    "        gradient = np.dot(X.T, loss) / n  #compute the gradients\n",
    "        z_cache.append(z.copy()) #store z value over iteration\n",
    "        z -= learning_rate * gradient  # update the value of z\n",
    "        if verbose:\n",
    "            print(f\"Epoch: {i} | Mean Squared Error: {J}\")\n",
    "            ax1.scatter(i,J)\n",
    "    \n",
    "    #Final evaluation after the epochs \n",
    "    y_hat = np.dot(X, z) # final predicted y\n",
    "    loss = y_hat - y\n",
    "    J = np.sum(loss ** 2) / (2 * n)  # cost function\n",
    "    squared_error.append(J)\n",
    "    z_cache.append(z.copy())\n",
    "       \n",
    "    return z, z_cache, squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read and Standardize the Data of Table 1(Stored as CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data from the CSV file\n",
    "price_data = genfromtxt('datasets/table1.csv', delimiter=',')\n",
    "X, y, meanX, stdX  = process_data(price_data) #call process_data function to standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closed form solution\n",
    "z = np.dot(np.linalg.inv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "y_hat = X@z #matrix multiplication\n",
    "z_closedform = z.copy()\n",
    "print(f\"Coeff Closed Form:{z_closedform}\")\n",
    "print(f\"MSE:{mse(X, y, z)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train using Batch Gradient Descend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call gradient descend\n",
    "z, z_cache, squared_error = batch_gradient_descent( X, y, learning_rate=0.1, epochs=80, verbose=True)\n",
    "print(f\"Coeff using GD:{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2.c\n",
    "#### Plot the Convergence of 'z': Animation\n",
    "**Re-run from beginning to replay as some variables gets overwritten afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize = (10, 7))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "ax.view_init(elev=2, azim=-44)\n",
    "print(\"Please wait while Animating Convergence....\")\n",
    "for i in range(len(z_cache)):\n",
    "    ax.cla() #clear axis\n",
    "    plot1 = ax.scatter3D(price_data[:, 0], price_data[:, 1], price_data[:, 2], s=250, c='r', marker='.', zorder=1, label=\"Given Data\")\n",
    "    \n",
    "    # Create Meshgrid from x, y\n",
    "    xlim = np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 50)\n",
    "    ylim = np.linspace(ax.get_ylim()[0], ax.get_ylim()[1], 50)\n",
    "    X_axis,Y_axis = np.meshgrid(xlim,ylim)\n",
    "    \n",
    "    #Plot plane from closed form coefficients\n",
    "    Z_axis = z_closedform[0] + z_closedform[1]*(X_axis-meanX[0])/stdX[0] + z_closedform[2]*(Y_axis-meanX[1])/stdX[1]\n",
    "    plot2 = ax.plot_surface(X_axis, Y_axis, Z_axis, alpha=0.5, zorder = 1, label=\"Closed Form\") #cmap='viridis'\n",
    "    \n",
    "    #Plot Plane from the gradient descend\n",
    "    Z_axis = z_cache[i][0] + z_cache[i][1]*(X_axis-meanX[0])/stdX[0] + z_cache[i][2]*(Y_axis-meanX[1])/stdX[1]\n",
    "    plot3 = ax.plot_surface(X_axis, Y_axis, Z_axis, alpha=0.5, zorder = 2, label=\"Gradient Descend\") #cmap='viridis'\n",
    "    \n",
    "    #Add plot attributed\n",
    "    plt.title(\"simple 3D scatter plot\")\n",
    "    ax.set_xlabel('House Size', fontweight ='bold') \n",
    "    ax.set_ylabel('Bedrooms', fontweight ='bold') \n",
    "    ax.set_zlabel('Price(millions)', fontweight ='bold')\n",
    "    \n",
    "    #Put Legends on the Plot\n",
    "    plot3._facecolors2d=plot3._facecolors3d\n",
    "    plot3._edgecolors2d=plot3._edgecolors3d\n",
    "    plot2._facecolors2d=plot2._facecolors3d\n",
    "    plot2._edgecolors2d=plot2._edgecolors3d\n",
    "    plt.legend()\n",
    "    fig.canvas.draw()\n",
    "print(\"Plotting Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2.d\n",
    "### 10 Fold Cross Validation of Housing Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "housing_data = genfromtxt('datasets/housing.txt', delimiter=',')\n",
    "X, y, meanX, stdX = process_data(housing_data) #preprocess the data\n",
    "\n",
    "# Scale down the values of y: as the values of y is in range 399 900\n",
    "# Divide y with 10^5 hence it will be in range [2, 5]\n",
    "y = y/(10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# prepare 10 fold cross validation\n",
    "kfold = KFold(10, True, 1)\n",
    "\n",
    "sum_mse = 0 #init mse sum with 0\n",
    "z = np.random.rand(3,1) #Initialize z with random values\n",
    "for train, test in kfold.split(X):\n",
    "    #kfold:True to use the z values from previous training\n",
    "    z, z_cache, squared_error = batch_gradient_descent( X[train], y[train], learning_rate=0.1, epochs=150, kfold=True, z=z)\n",
    "    sum_mse += mse(X[test], y[test], z)\n",
    "\n",
    "#Compute the average of mean squared error over 10 folds of testing\n",
    "avg_mse = sum_mse/10\n",
    "print(f\"Coeff(z) from KFold: {z}\" )\n",
    "print(f\"Mean Squared Error(10 Folds): {avg_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results compared by solving with Closed Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closed for solution\n",
    "z = np.dot(np.linalg.inv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "y_hat = X@z #matrix multiplication\n",
    "z_closedform = z.copy()\n",
    "print(f\"Coeff Closed Form:{z_closedform}\")\n",
    "print(f\"MSE Closed Form:{mse(X, y, z)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "Hence it's validated that 10-Fold validation produces results comprable to closed form solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
